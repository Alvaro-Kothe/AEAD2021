## Dados de dígitos manuscritos


```{r carrega mnist}
load("../dados/dados_mnist.rdata")
```




```{r separa treino validacao}
# Cria os índices para treino e validação para a comparação dos modelos
set.seed(1)

perc_val <- .25
n <- nrow(x_treino)
idx_val <- sample(seq_len(n), n * perc_val)

idx_tr <- setdiff(seq_len(n), idx_val)
```

No conjunto de dados de dígitos manuscritos, temos 60000 dígitos escritos a mão em imagens de dimensão $28 \times 28$. O conjunto de dados foi separado em conjunto de treino e validação, onde `r perc_val * 100`\% dos dados foi utilizado como conjunto de validação, ou seja, uma amostra de `r length(idx_tr)` dígitos será utilizada para construir os modelos, e os dígitos restantes serão utilizados para avaliar a qualidade de ajuste dos modelos.

Em seguida os pixels foram normalizados para a escala $[0, 1],$ (equivalente a por a imagem na escala de cinza) para que alguns dos modelos utilizados convirja mais rápido. 

```{r}
# Como as matrizes das imagens possuem muito zero, uma matriz esparsa é
# apropriada para poupar espaço. Mas será utilizada apenas no glmnet.
x_treino <- x_treino / 255.
x_mnist_sparse <- Matrix(x_treino, sparse = TRUE)
y_treino <- factor(y_treino, levels = 0:9)
```

Com os dados normalizados e separados em conjunto de treino e teste, serão construídos três modelos para realizar as predições das imagens:

- Lasso Multinomial
- Boosting
- Rede Neural Convolucional

### Modelo linear com regularização

Como o problema é diferenciar 10 dígitos utilizando 784 pixels, isso indica que o problema é de classificação com mais de duas classes. Logo, será ajustado um modelo multinomial. E como diversos pixels geralmente não são preenchidos para escrever os dígitos, é interessante realizar selecionar os pixels importantes para a classificação de cada dígito. Por isso, será ajustado um modelo Lasso Multinomial. Para a escolha do parâmetro de penalização foi gerado 100 hiper-parâmetros de penalização, e foi escolhido o melhor hiper-parâmetro através de validação cruzada utilizando apenas o conjunto de treino.



```{r modelo cv lasso mnist}
if (!file.exists("../modelos/fit_mnist_lasso_cv.rds")) {
  # Devido a demora para ajustar esse modelo, ele ficará salvo no computador
  # para poupar o tempo de ajusta-lo novamente
  set.seed(2)
  fit_mnist_lasso_cv <- cv.glmnet(
    x_mnist_sparse[-idx_val, ], y_treino[-idx_val],
    family = "multinomial", type.measure = "class", # regressão multinomial
    nfolds = 5, # 5 validações cruzadas
    parallel = TRUE # Utiliza paralelização para acelear o ajuste.
  )
  saveRDS(fit_mnist_lasso_cv, "../modelos/fit_mnist_lasso_cv.rds")
} else {
  fit_mnist_lasso_cv <- readRDS("../modelos/fit_mnist_lasso_cv.rds")
}
```


```{r lasso mnist}
# Como apresentado na aula de lasso, após selecionado o lambda,
# ajusta o modelo com todos os dados de treino
if (!file.exists("../modelos/fit_mnist_lasso.rds")) {
  # Também para poupar tempo, o modelo ficará salvo no computador

  fit_mnist_lasso <- glmnet(
    x_mnist_sparse[-idx_val, ], y_treino[-idx_val],
    family = "multinomial", type.measure = "class", # regressão multinomial
    # Ajustar com os mesmos lambdas para não soltar erro no ajuste.
    lambda = fit_mnist_lasso_cv$lambda
  )

  saveRDS(fit_mnist_lasso, "../modelos/fit_mnist_lasso.rds")
} else {
  fit_mnist_lasso <- readRDS("../modelos/fit_mnist_lasso.rds")
}
```



```{r pred lasso}
pred_las_f <- predict(fit_mnist_lasso,
  x_mnist_sparse[idx_val, ],
  s = fit_mnist_lasso_cv$lambda.min,
  type = "class"
)

pred_las_d <- predict(fit_mnist_lasso,
  x_mnist_sparse[-idx_val, ],
  s = fit_mnist_lasso_cv$lambda.min,
  type = "class"
)

acuracias_mnist <- tibble(
  Modelo = "Multinomial Lasso",
  "Acurácia Dentro" = mean(pred_las_d == y_treino[-idx_val]),
  "Acurácia Fora" = mean(pred_las_f == y_treino[idx_val])
)
```

Na figura \@ref(fig:pixels-importantes-lasso) é apresentado os pixels que não foram nulos para a classificação de cada dígito, com o dígito referente em verde no canto superior esquerdo de cada imagem.

```{r pixels-importantes-lasso, fig.cap="Pixels não nulos para cada dígito pelo modelo lasso."}
plot_mnist <- function(x, text = NULL, col = "white", tx = .05, ty = .95) {
  matriz <- matrix(x, ncol = 28, byrow = TRUE)

  imagem <- t(apply(matriz, 2, rev))

  image(imagem, col = grey.colors(255), axes = FALSE)
  text(tx, ty, col = col, cex = 1.2, text)

  return(imagem)
}

# pega os coeficientes diferentes de zero, sem intercepto
coef_nnulo <- lapply(
  coef(fit_mnist_lasso, s = fit_mnist_lasso_cv$lambda.min),
  function(x) (x != 0)[-1, ]
)

# Coloca os gráficos em um grid 2x5
layout(matrix(1:10, nrow = 2, byrow = TRUE))
par(mar = c(.1, .1, .1, .1), xaxs = "i", yaxs = "i")


invisible(
  mapply(plot_mnist, x = coef_nnulo, text = names(coef_nnulo), col = "green")
)
```

Pela Figura \@ref(fig:pixels-importantes-lasso), é possível ver os principais pixels para a classificação de cada dígito. Pode-se notar que a partir dos pixels não nulos, é possível desenhar o dígito que deseja-se classificar.

### Modelo baseado em árvore

Existe vários tipos possíveis de modelos baseados em árvore que podem ser utilizados. Porém, para casos de classificação de imagem, mais especificamente a classificação de dígitos do MNIST, modelos de *boosting* conseguem oferecer um bom ajuste. Por conta disso, será ajustado um modelo de boosting utilizando o pacote [XGBoost](https://xgboost.ai/).


```{r}

# XGBoost pede que a variável resposta entre como numérica. É definido dentro
# dos parâmetros que o objetivo do modelo é classificação de 10 classes.
y_treino_num <- as.integer(as.character(y_treino))

dtrain <- xgb.DMatrix(x_mnist_sparse[idx_tr, ], label = y_treino_num[idx_tr])


xgb_grid <- expand_grid(
  objective = "multi:softmax",
  num_class = 10, # 10 classes (digitos 0 a 9)
  eval_metric = "mlogloss", # entropia de multiplas classes
  eta = c(0.1, 0.05, 0.01),
  max_depth = 2:6,
  min_child_weight = c(1, 2, 3, 4, 5),
  subsample = 1
)



xgb_search <- function(dmatrix, data_val, label_val,
                       param_grid, nrounds = 100) {
  param_grid_rows <- split(param_grid, seq_len(nrow(param_grid)))
  param_grid_list <- lapply(param_grid_rows, as.list)
  acc <- sapply(param_grid_list, function(params) {
    modelo <- xgb.train(
      params = params,
      data = dmatrix,
      nrounds = nrounds
    )

    mean(predict(modelo, data_val) == label_val)
  })
  idx_melhor <- which.max(acc)
  list(
    best_par = param_grid_list[[idx_melhor]],
    acuracias = acc
  )
}
```




```{r eval=FALSE, include=FALSE}
# Demora muito para rodar, não será mais avaliado
# só toma os melhores parâmetros.
accuracias <- xgb_search(dtrain,
  x_mnist_sparse[idx_val, ], y_treino_num[idx_val],
  param_grid = xgb_grid
)
## Melhores parâmetros
# list(objective = "multi:softmax", num_class = 10, eval_metric = "mlogloss",
#     eta = 0.1, max_depth = 6L, min_child_weight = 4, subsample = 1)

# acuracias variaram de 0,78 ate 0,97
```

Para a seleção dos hiper-parâmetros, foi ajustado 75 modelos para selecionar a taxa de aprendizagem (`eta`), a profundidade máxima da árvore (`max_depth`) e a perda mínima para criar outra partição da árvore (`min_child_weight`). Os parâmetros escolhidos foram:

- eta: 0.1
- max_depth: 6
- min_child_weight: 4

O número de árvores foi controlado pelo conjunto de validação, porém foi definido que o número máximo de árvores seria 500.

```{r xgboost mnist, cache=TRUE, include=FALSE}


dval <- xgb.DMatrix(x_mnist_sparse[idx_val, ], label = y_treino_num[idx_val])


params <- list(
  objective = "multi:softmax", # Classificação (predict solta a classe)
  num_class = 10, # 10 classes (digitos 0 a 9)
  eval_metric = "mlogloss", # entropia de multiplas classes
  eta = .1, # taxa de aprendizagem
  max_depth = 6, # A profundidade máxima da árvore
  min_child_weight = 4,
  nthread = parallel::detectCores() - 1 # número de processadores lógicos
  # utilizados.
)

# Argumento para controlar o número de árvores do modelo a partir do conjunto
# de validação. Isso evita *overfitting*.
watchlist <- list(train = dtrain, eval = dval)

set.seed(1234)

xgboost_mnist <- xgb.train(
  params,
  dtrain,
  watchlist = watchlist,
  nrounds = 500, # Máximo de iterações
  early_stopping_rounds = 5, # Parar após 5 iterações sem melhora
  print_every_n = 10
)
```


```{r pred xgboost}
acuracias_mnist <- acuracias_mnist %>%
  add_row(
    Modelo = "Boosting",
    "Acurácia Fora" = mean(
      predict(xgboost_mnist, x_mnist_sparse[idx_val, ]) == y_treino[idx_val]
    ),
    "Acurácia Dentro" = mean(
      predict(xgboost_mnist, x_mnist_sparse[idx_tr, ]) == y_treino[idx_tr]
    )
  )
```



### Redes neurais







```{r mnist array}
dim_imagem <- 28
# array_reshape funciona igual ao numpy.reshape
# -1 indica que a dimensão será o que sobrar para completar o array.
x_treino_ar <-
  array_reshape(x_treino[idx_tr, ], c(-1, dim_imagem, dim_imagem, 1))
x_val_ar <-
  array_reshape(x_treino[idx_val, ], c(-1, dim_imagem, dim_imagem, 1))

y_treino_tc <- to_categorical(y_treino_num[idx_tr], 10)
y_val_tc <- to_categorical(y_treino_num[idx_val], 10)


#### Parametros para o keras

input_shape <- c(dim_imagem, dim_imagem, 1)
batch_size <- 64
epochs <- 50

val_data = list(x_val_ar, y_val_tc)

callbacks <- list(
  callback_early_stopping(patience = 5, restore_best_weights = TRUE)
)
```

```{r, eval=FALSE, include=FALSE}


tensorflow::set_random_seed(42)

rn_base = keras_model_sequential() %>%
    layer_conv_2d(filters = 32, kernel_size = c(5, 5), activation = "relu",
    input_shape = input_shape) %>%
    layer_max_pooling_2d() %>%
    layer_flatten() %>%
    layer_dense(512, activation = "relu") %>%
    layer_dense(10, activation = "softmax")

rn_base %>% compile(
  loss = loss_categorical_crossentropy,
  optimizer = optimizer_adam(learning_rate = 1e-4),
  metrics = c("accuracy")
)

rn_base %>% fit(
  x_treino_ar, y_treino_tc,
  batch_size = batch_size,
  epochs = epochs,
  callbacks = callbacks,
  validation_data = val_data,
  verbose=2
)

# rn_base %>% evaluate(x_val_ar, y_val_tc)

#       loss   accuracy 
# 0.03541163 0.98966664 
```


Para o modelo de rede neural, foi considerado uma rede neural convolucional base com acurácia 0.9897. Para a rede base, foi utilizada uma camada convolucional e uma camada escondida, todas camadas tiveram função de ativação `relu`. O otimizador utilizado foi o `Adam` com taxa de aprendizagem 0,0001.


```{r cnn-final}

tensorflow::set_random_seed(42)

# Adiciona camada convolucional e dropout
rn_mnist <- keras_model_sequential() %>%
  layer_conv_2d(
    filters = 32, kernel_size = c(5, 5), activation = "relu",
    input_shape = input_shape
  ) %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
    layer_dropout(.2) %>%
  layer_conv_2d(filters = 64, kernel_size = c(5, 5), activation = "relu") %>%
  layer_max_pooling_2d(pool_size = c(2, 2)) %>%
      layer_dropout(.2) %>%
  layer_flatten() %>%
  layer_dense(512, "relu") %>%
  layer_dropout(.2) %>%
  layer_dense(units = 10, activation = "softmax")

rn_mnist %>% compile(
  loss = loss_categorical_crossentropy,
  optimizer = optimizer_nadam(),
  metrics = c("accuracy")
)



historico <- rn_mnist %>% fit(
  x_treino_ar, y_treino_tc,
  batch_size = batch_size,
  epochs = epochs,
  callbacks = callbacks,
  validation_data = val_data,
  verbose=2
)

# rn_mnist %>% evaluate(x_val_ar, y_val_tc)
# 
#       loss   accuracy 
# 0.02965022 0.99213332 

```


Em seguida foi ajustado diversas redes, manipulando a quantidade de camadas intermediárias, adicionando camada de `dropout` e manipulando o otimizador ([Ruder](https://ruder.io/optimizing-gradient-descent/) apresentou diversos otimizadores baseados em gradiente descendente). A estrutura da rede final é:

- camada convolucional com 32 filtros, janela deslizante $5 \times 5$ e ativação relu;
- camada de `max_pooling` de dimensão $2 \times 2$;
- camada de `dropout` com taxa 0.2;
- camada convolucional com 64 filtros, janela deslizante $5 \times 5$ e ativação relu;
- camada de `max_pooling` de dimensão $2 \times 2$;
- camada de `dropout` com taxa 0.2;
- camada de achatamento (`flatten`);
- camada `dense` com 512 neurônios e ativação relu;
- camada de `dropout` com taxa 0.2;
- a última camada é uma `dense` com ativação softmax de 10 neurônios para classificar o dígito.

O otimizador escolhido foi o `nadam` que é similar ao `adam` mas contém momento para acelerar a convergência. Foi definido que o ajuste seria parado se houvesse 5 épocas sem melhora, e o modelo foi ajustado em lotes de tamanho `r batch_size`.


```{r pred-rede, cache=TRUE}

pred_mnist_rn_val <- predict(rn_mnist, x_val_ar) %>%
  k_argmax() %>%
  as.integer()

pred_mnist_rn_treino <- predict(rn_mnist, x_treino_ar) %>%
  k_argmax() %>%
  as.integer()

acuracias_mnist <- acuracias_mnist %>%
  add_row(
    Modelo = "Rede Neural Convolucional",
    "Acurácia Fora" = mean(
      pred_mnist_rn_val == y_treino[idx_val]
    ),
    "Acurácia Dentro" = mean(
      pred_mnist_rn_treino == y_treino[idx_tr]
    )
  )
```

## Comparação dos modelos

Para a comparação dos modelos será utilizado a acurácia. Na Tabela \@ref(tab:tabela-modelos) é apresentado a acurácia para o conjunto de treino (Acurácia Dentro) e validação (Acurácia Fora).

```{r tabela-modelos}
kable(acuracias_mnist,
  caption = "Acurácias dos modelos ajustados para o conjunto de dados MNIST.",
  booktabs = TRUE, linesep = ""
) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```


Podemos ver pela Tabela \@ref(tab:tabela-modelos) que o modelo de rede neural foi o que teve as melhores predições no conjunto de validação. Nota-se também que o modelo de Boosting predizeu perfeitamente no conjunto de treino, o que mostra que esse modelo conseguiu decorar o conjunto de treino. Porém, conseguiu predizer corretamente na maior parte no conjunto de validação.

Como o modelo de rede neural convolucional foi o que teve a maior acurácia no conjunto de validação, ele será o modelo escolhido para realizar as predições no conjunto de teste. Para apresentar um pouco das predições do modelo escolhida, na Figura \@ref(fig:matriz-confusao-rede) é apresentado a matriz de confusão do modelo no conjunto de validação.

```{r matriz-confusao-rede, fig.cap="Matriz de confusão para o modelo de rede neural convolucional para o conjunto de dados de validação."}
confusion_matrix <- as.data.frame(
  table(
    predito = pred_mnist_rn_val,
    verdadeiro = y_treino[idx_val]
  )
)

ggplot(confusion_matrix, aes(verdadeiro, predito)) +
  geom_tile(aes(fill = Freq), show.legend = FALSE) +
  geom_text(aes(label = Freq), color = "black") +
  scale_fill_gradient(low = "white", high = "dodgerblue3", trans = "log1p") +
  labs(x = "Observado", y = "Predito") +
  theme_minimal()
```

Pela Figura \@ref(fig:matriz-confusao-rede), não se percebe um dígito em que o modelo apresentou dificuldades de prever.

Na Figura \@ref(fig:rn-plt-pred) se encontram algumas predições no conjunto de validação. As predições corretas estão na cor verde, e as incorretas estão na cor vermelha com a predição correta dentro dos parênteses.

```{r rn-plt-pred, fig.cap="Amostra das classificações da rede neural para o conjunto de validação."}
set.seed(1)

total_graficos <- 6 * 6
prop_incorretos <- .25
graficos_incorretos <- floor(total_graficos * prop_incorretos)
graficos_corretos <- total_graficos - graficos_incorretos

# Pega índices de predições corretas e incorretas
idx_plot <- sample(c(
  sample(which(pred_mnist_rn_val != y_treino[idx_val]), graficos_incorretos),
  sample(which(pred_mnist_rn_val == y_treino[idx_val]), graficos_corretos)
))

# Define as cores para as predições corretas e incorretas
cores <- ifelse(idx_plot %in% which(pred_mnist_rn_val == y_treino[idx_val]),
  "green", "red"
)

# Texto nos gráficos
texto <- ifelse(idx_plot %in% which(pred_mnist_rn_val == y_treino[idx_val]),
  pred_mnist_rn_val[idx_plot],
  paste0(
    pred_mnist_rn_val[idx_plot], "(",
    y_treino[idx_val][idx_plot], ")"
  )
)

# Cria lista de matrizes para plotar
plot_matrixes <- lapply(
  idx_val[idx_plot],
  function(x) x_treino[x, ]
)

layout(matrix(seq_len(total_graficos),
  nrow = sqrt(total_graficos),
  byrow = TRUE
))
par(mar = c(.1, .1, .1, .1))


invisible(
  mapply(plot_mnist,
    x = plot_matrixes,
    text = texto, col = cores, tx = .9, ty = .1
  )
)
```

Pela Figura \@ref(fig:rn-plt-pred), nota-se alguns dígitos que são facilmente reconhecíveis, porém o modelo predizeu incorretamente. Mas como não se espera que um modelo consiga acertar em todo o conjunto de validação, e como ele teve uma ótima acurácia, ele será o modelo escolhido para realizar as predições no conjunto de teste.

```{r}
load("../dados/dados_mnist_teste.rdata")

# Transforma o conjunto de treino para a predição
x_teste_ar <- array_reshape(x_teste / 255., c(-1, dim_imagem, dim_imagem, 1))

predicoes <- predict(rn_mnist, x_teste_ar) %>%
  k_argmax() %>%
  as.integer()

write.csv(data.frame(y_pred = predicoes),
  file = glue("mnist_{nusp}_{meunome}.csv")
)
```
