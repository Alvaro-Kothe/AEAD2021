## Dados de chuva e vazão no Rio São Francisco


o que fazer:
- Heatmap
- Densidades
- Apresentar o exemplo do skit-learn

```{r dados sao francisco}
load("../dados/dados_rio_sf.rdata")
```


No conjunto de dados sobre a vazão no rio são francisco, temos `r nrow(dados_treino)` semanas de coletas de vazão e precipitação de diversas estações. O objetivo é predizer a vazão na estação 46998000 na semana seguinte.

O conjunto de dados possui diversas informações faltando, e comparado ao conjunto de dados de dígitos MNIST, não possui muitas observações. Por isso, para o tratamento e seleção de modelos será considerado a seguinte abordagem:

- Imputação: Será utilizado todo conjunto de treino disponibilizado;
- Tratamento
- Seleção de modelo: Será utilizado validação cruzada para comparar os modelos considerando o erro absoluto médio;
- Embedding



### Correção de assimetria e escala

É recomendado realizar transformações nas variáveis para que elas sejam normalmente distribuídas. O pacote *scikit-learn* fez um [exemplo](https://scikit-learn.org/stable/auto_examples/compose/plot_transformed_target.html#sphx-glr-auto-examples-compose-plot-transformed-target-py) para apresentar as vantagens de construir os modelos com a variável resposta transformada e em seguida realiza a transformação inversa para obter melhores predições.

A Figura \@ref(fig:grafico-densidade-vazao) apresenta as densidades das vazões e precipitações das estações até o quantil de 90\% para melhor visualização.


```{r grafico-densidade-vazao, fig.cap="Gráfico de densidades das estações, utilizando até o quantil 90\\% de todas as vazões."}
# retira vazões muito altas para melhorar a visibilidade do gráfico
dados_vazoes_longo <- treino_sf %>%
  pivot_longer(
    all_of(colunas_vazoes),
    names_to = "estacao",
    values_to = "vazao"
  )


dados_vazoes_longo %>%
  filter(vazao < quantile(vazao, .90, na.rm = TRUE)) %>%
  ggplot(aes(vazao, color = estacao, fill = estacao)) +
  geom_density(show.legend = FALSE, alpha = .3) +
  labs(x = "Vazão", y = "Densidade")
```


Na Figura \@ref(fig:densidade-resp) é apresentado a densidade da variável que deseja-se estimar.

```{r densidade-resp, fig.cap="Gráfico de densidade da estação resposta"}
ggplot(treino_sf, aes(Y)) +
  geom_density() +
  labs(
    x = glue("Vazão da estação {codigo_estacao_resposta}"),
    y = "Densidade"
  )
```

Pelas Figuras \@ref(fig:grafico-densidade-vazao) e \@ref(fig:densidade-resp), nota-se as vazões são bastante assimétricas. Por isso, será aplicado a transformação $\log(x + 1)$ em todas as vazões e precipitações para reduzir a assimetria. Na figura \@ref(fig:densidades-transformadas) são apresentadas todas as vazões e precipitações transformadas das estações preditoras e a vazão da variável resposta.

```{r densidades-transformadas, fig.cap="Gráfico de densidade das variáveis transformadas.", fig.subcap=c("Todas as estações", "Variável resposta"), out.width="50%"}

dados_vazoes_longo %>%
  ggplot(aes(log1p(vazao), color = estacao, fill = estacao)) +
  geom_density(show.legend = FALSE, alpha = .3) +
  labs(x = "Vazão", y = "Densidade")

ggplot(treino_sf, aes(log1p(Y))) +
  geom_density() +
  labs(
    x = glue("Vazão da estação {codigo_estacao_resposta}"),
    y = "Densidade"
  )
```
Nota-se pela \@ref(fig:densidades-transformadas), que a transformação $\log(x+1)$ conseguiu reduzir bastante a assimetria.

```{r}
# Transforma
x_trans <- log1p(as.matrix(treino_sf[, -1]))
```

Em seguida, para remover o efeito da escala das vazões e precipitações, essas medidas foram padronizadas.


```{r}
# padroniza
standardizer <- preProcess(x_trans, method = c("center", "scale"))
x_treino <- predict(standardizer, x_trans)
y_treino = log1p(treino_sf[,1])
```





Para a predição da estação 46998000, será utilizado apenas os dados das vazões da semana anterior, incluindo a vazão da própria estação 46998000. Além disso, mesmo que os dados estejam padronizados, a vazão da semana seguinte será predita com a transformação $\log(x+1)$. Para conjunto de teste será aplicado a transformação $\exp(x) - 1$ nas predições para que a vazão seja apresentada na escala original.

Para ilustrar as transformações feitas, e o que será utilizado para ajustar os modelos, na Tabela \@ref(tab:matriz-x) é apresentado as 6 primeiras observações do conjunto de treinamento, em que na primeira coluna tem-se a vazão da semana seguinte que deseja-se prever com a transformação $\log(x+1)$.  As demais colunas são as 6 primeiras colunas das vazões da semana anterior já transformadas e padronizadas.

```{r matriz-x}
cbind(
  "$\\log(Y + 1)$" = y_treino,
  x_treino[, 1:6]
) %>%
  head(6) %>%
  kable(
    caption = paste(
      "Primeiras linhas e colunas",
      "do conjunto de treinamento,",
      "com a primeira coluna sendo a variável resposta transformada",
      "(vazão da semana seguinte)."
    ),
    booktabs = TRUE, linesep = "", escape = TRUE, digits = 3
  ) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```


### Ajuste dos modelos

Como já definido, os modelos serão comparados por validação cruzada. O método de validação cruzada escolhido foi o *k-folds*, com $k=10$, ou seja, será utilizado 9 amostras para ajustar os modelos, e uma amostra para validação. Esse processo será repetido 10 vezes. A medida utilizada para comparar os modelos será o erro médio absoluto.

Os modelos que serão ajustados são:

- Modelos lineares com regularização:
    - Lasso
    - Ridge
- Modelos baseados em árvores:
    - Floresta aleatória
    - Boosting utilizando o pacote [XGBoost](https://xgboost.ai/)
- Rede Neural

```{r}
cv_folds <- 10

folds <- sample(1:10, size = length(y_treino), replace = TRUE)
```


Para os modelos de Lasso e Ridge, primeiro foi escolhido o melhor parâmetro de penalização através da validação cruzada, utilizando as mesmas amostras já definidas pelo *k-fold*. Em seguida, dado os parâmetros de penalização que apresentaram o menor erro de validação cruzada, foi feito novamente a validação cruzada para obter o erro médio absoluto de cada *fold*


```{r}
lambda_lasso <-
  cv.glmnet(x_treino,
    y_treino,
    foldid = folds
  )$lambda.min

lambda_ridge <-
  cv.glmnet(x_treino,
    y_treino,
    foldid = folds,
    alpha = 0
  )$lambda.min
```

```{r}
scores <- list()

# Função util  para obter os erros de validação cruzada.
cv_mae <- function(modelo, x, y, folds, ...) {
  unique_folds <- unique(folds)
  sapply(unique_folds, function(fold) {
    idx_val <- folds == fold

    x_tr <- x[!idx_val, ]
    y_tr <- y[!idx_val]
    x_val <- x[idx_val, ]
    y_val <- y[idx_val]


    fit_ <- modelo(x_tr, y_tr, ...)

    preds_ <- predict(fit_, x_val)

    MAE(preds_, y_val)
  })
}
```


Maior parte do modelo de floresta aleatória foi ajustado com os valores padrão da função `randomForest` do pacote com o mesmo nome. Mas para previnir sobreajuste foi definido que a profundidade máxima de cada árvore seria 15.

O modelo de Boosting consegue facilmente sobreajustar os dados de treino. Porém, o pacote XGBoost fornece diversos hiper-parâmetros para controlar o ajuste. Por isso foi utilizada uma taxa de aprendizagem $\eta = 0.01$,  profundidade máxima da árvore 4, em cada árvore utilizava apenas 70\% das observações e dos preditores. Além disso, a perda mínima para a prolongar a árvore seria 0.6, foi utilizada regularização de primeira ordem e foi utilizado o número de árvores igual a 1000.


```{r scores, cache=TRUE}

set.seed(115)

scores[["Lasso"]] <- cv_mae(glmnet,
                            x_treino, y_treino,  folds,
  alpha = 1, lambda = lambda_lasso
)
scores[["Ridge"]] <- cv_mae(glmnet,
                            x_treino, y_treino,  folds,
  alpha = 0, lambda = lambda_ridge
)

scores[["Floresta Aleatória"]] <- cv_mae(randomForest,
  x_treino, y_treino, folds,
  maxnodes = 15
)


params <- list(
  objective = "reg:squarederror",
  eta = .01, # taxa de aprendizagem baixa para evitar overfitting.
  max_depth = 4, # A profundidade máxima da árvore
  gamma = .6, # Perda mínima para uma nova partição  da folha.
  subsample = .7, # Utiliza menos dados para ajustar o modelo
  colsample_bytree = .7, # Utiliza menos colunas
  reg_alpha = 5e-5, # Regularização L1, similar ao lasso
  nthread = parallel::detectCores() - 1 # número de processadores lógicos
  # utilizados.
)

scores[["Boosting"]] <- cv_mae(xgboost,
                               x_treino, y_treino, folds,
  nrounds = 1000, params = params, verbose = 0
)
```

Para o modelo de redes neuras, utilizou-se um modelo simples que foi é treinado em 50 épocas em lotes de tamanho 64 (`batch_size`). A estrutura do modelo é:

- camada `dense` com 128 neurônios e ativação sigmóide;
- camada `dense` com 64 neurônios e ativação sigmóide;
- a última camada é uma `dense` com ativação linear;

```{r rede-neural}
cria_rede_sf <- function() {
  modelo <- keras_model_sequential() %>%
    layer_dense(128, activation = "sigmoid", input_shape = ncol(x_treino)) %>%
    layer_dense(64, activation = "sigmoid") %>%
    layer_dense(1)

  modelo %>%
    compile(
      optimizer = optimizer_adam(),
      loss = loss_mean_squared_error()
    )
}

tensorflow::set_random_seed(1234)

# Não consegui aplicar a minha função para o keras, logo será feito na mao
scores[["Rede Neural"]] <- sapply(unique(folds), function(fold) {
  idx_val <- folds == fold

  x_tr <- x_treino[!idx_val, ]
  y_tr <- y_treino[!idx_val]
  x_val <- x_treino[idx_val, ]
  y_val <- y_treino[idx_val]

  modelo <- cria_rede_sf()

  modelo %>% fit(x_tr, y_tr, verbose = 0, batch_size = 64, epochs = 50)

  modelo %>%
    predict(x_val) %>%
    MAE(y_val)
})
```

Para cada modelo

```{r boxplot-scores, fig.cap="Boxplot do erro médio absoluto por modelo pela validação cruzada."}
scores_tbl <- bind_cols(scores) %>%
  pivot_longer(everything(), names_to = "Modelo", values_to = "mae")
scores_tbl %>%
  ggplot(aes(Modelo, mae)) +
  geom_boxplot() +
  stat_summary(
    fun = mean, geom = "point", shape = 20,
    size = 2, color = "red"
  ) +
  labs(x = "Modelo", y = "Erro Médio Absoluto") +
  coord_flip()
```

```{r media-scores}
# Esse cógido da problema no lintr
scores_tbl %>%
  group_by(Modelo) %>%
  summarise(
    media = mean(mae),
    desvio = sd(mae)
  ) %>%
  arrange(media) %>%
  kable(
    caption = paste(
      "Média e desvio do erro médio absoluto",
      "dos modelos pela validação cruzada"
    ),
    col.names = c("Modelo", "Média", "Desvio"),
    booktabs = TRUE, linesep = ""
  ) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```


```{r}
lasso_full <- glmnet(x_treino, y_treino, alpha = 1, lambda = lambda_lasso)
ridge_full <- glmnet(x_treino, y_treino, alpha = 0, lambda = lambda_ridge)
rf_full <- randomForest(x_treino, y_treino, ntree = 500, maxnodes = 15)
xgboost_full <- xgboost(x_treino, y_treino,
  nrounds = 1000, params = params,
  verbose = 0
)

mistura_predicoes <- function(x) {
  .3 * predict(xgboost_full, x) +
    .25 * predict(rf_full, x) +
    .25 * predict(lasso_full, x) +
    .2 * predict(ridge_full, x)
}
```

### Escolha do modelo

Pela Figura \@ref(fig:boxplot-scores) e Tabela \@ref(tab:media-scores), os melhores modelos foram o Lasso, Ridge, Floresta Aleatória e Boosting, que apresentaram erro baixo e pouca variabilidade  pela validação cruzada. Por isso, para as predições, será tomado a média ponderada do valor predito para esses modelos. Em seguida será aplicado a transformação $\exp(x) - 1$ na média ponderada para devolver a vazão predita para a escala original. Ou seja, as predições do conjunto de teste será dada por
\[\hat y = \exp\{0.3 \hat y_{B} + 0.25 \hat y_{F} +
0.25 \hat y_{L} + 0.2 \hat y_{R}\} - 1,\]
onde $\hat y_{B}, \hat y_{F}, \hat y_{L}, \hat y_{R},$ são as predições de Boosting, Floresta aleatória, Lasso e Ridge, respectivamente.


justificar
