## Dados de chuva e vazão no Rio São Francisco


```{r dados sao francisco}
load("../dados/dados_rio_sf.rdata")
```

Na Figura \@ref(fig:resp-lag) é apresentado o gráfico de dispersão da estação resposta contra a sua defasagem de primeira ordem.
```{r resp-lag, fig.cap="Gráfico da resposta contra a sua defasagem."}
ggplot(treino_sf, aes(`46998000`, Y)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(y = "Resposta", x = "Lag_1")
```

```{r corplot, fig.cap="Heatmap das variáveis com a maior correlação com a variável resposta."}

n_var <- 15

corr <- cor(treino_sf, use = "pairwise.complete.obs")
# Ordena pela correlação com a variável resposta `Y`

cor_srted <- order(abs(corr[, "Y"]), decreasing = TRUE)[seq_len(n_var)]

corplot <- corr[cor_srted, cor_srted]

corrplot.mixed(corplot,
  tl.pos = "lt", tl.col = "black",
  number.cex = .6
)
```

```{r eval=FALSE, include=FALSE}
estacoes %>%
  filter(estacao_codigo %in% colnames(corplot)[1:6]) %>%
  head()
```
Todas as bacias que apresentaram correlação acima de 0.9 com a variável resposta `Y`, pertencem ao rio são francisco.


No conjunto de dados sobre a vazão no rio são francisco, temos `r nrow(treino_sf)` semanas de coletas de vazão e precipitação de diversas estações. O objetivo é predizer a vazão na estação 46998000 na semana seguinte.

O conjunto de dados possui diversas informações faltando, e comparado ao conjunto de dados de dígitos MNIST, não possui muitas observações. Por isso, para o tratamento e seleção de modelos será considerado a seguinte abordagem:

- Imputação: Será utilizado todo conjunto de treino disponibilizado;
- Tratamento
- Seleção de modelo: Será utilizado validação cruzada para comparar os modelos considerando o erro absoluto médio;
- Embedding



### Correção de assimetria e escala

É recomendado realizar transformações nas variáveis para que elas sejam normalmente distribuídas. O pacote *scikit-learn* fez um [exemplo](https://scikit-learn.org/stable/auto_examples/compose/plot_transformed_target.html#sphx-glr-auto-examples-compose-plot-transformed-target-py) para apresentar as vantagens de construir os modelos com a variável resposta transformada e em seguida realiza a transformação inversa para obter melhores predições. Um dos principais motivos para realizar esse tipo de transformação é para que pontos discrepantes não tenham um peso tão grande no modelo.

A Figura \@ref(fig:grafico-densidade-vazao) apresenta as densidades das vazões e precipitações das estações até o quantil de 90\% para melhor visualização.


```{r grafico-densidade-vazao, fig.cap="Gráfico de densidades das estações, utilizando até o quantil 90\\% de todas as vazões."}
# retira vazões muito altas para melhorar a visibilidade do gráfico
dados_vazoes_longo <- treino_sf %>%
  pivot_longer(
    everything(),
    names_to = "estacao",
    values_to = "vazao"
  )


dados_vazoes_longo %>%
  filter(vazao < quantile(vazao, .90, na.rm = TRUE)) %>%
  ggplot(aes(vazao, color = estacao, fill = estacao)) +
  geom_density(show.legend = FALSE, alpha = .3) +
  labs(x = "Vazão", y = "Densidade")
```


Na Figura \@ref(fig:densidade-resp) é apresentado a densidade da variável que deseja-se estimar.

```{r densidade-resp, fig.cap="Gráfico de densidade da estação resposta"}
ggplot(treino_sf, aes(Y)) +
  geom_density() +
  labs(
    x = "Vazão da estação 46998000",
    y = "Densidade"
  )
```

Pelas Figuras \@ref(fig:grafico-densidade-vazao) e \@ref(fig:densidade-resp), nota-se as vazões são bastante assimétricas. Por isso, será aplicado a transformação $\log(x + 1)$ em todas as vazões e precipitações para reduzir a assimetria. Na figura \@ref(fig:densidades-transformadas) são apresentadas todas as vazões e precipitações transformadas das estações preditoras e a vazão da variável resposta.

```{r densidades-transformadas, fig.cap="Gráfico de densidade das variáveis transformadas.", fig.subcap=c("Todas as estações", "Variável resposta"), out.width="50%"}

dados_vazoes_longo %>%
  ggplot(aes(log1p(vazao), color = estacao, fill = estacao)) +
  geom_density(show.legend = FALSE, alpha = .3) +
  labs(x = "Vazão", y = "Densidade")

ggplot(treino_sf, aes(log1p(Y))) +
  geom_density() +
  labs(
    x = "Vazão da estação 46998000",
    y = "Densidade"
  )
```
Nota-se pela \@ref(fig:densidades-transformadas), que a transformação $\log(x+1)$ conseguiu reduzir bastante a assimetria.

```{r}
# Transforma
x_trans <- log1p(as.matrix(treino_sf[, -1]))
```

Em seguida, para remover o efeito da escala das vazões e precipitações, essas medidas foram padronizadas.


```{r}
# padroniza
standardizer <- preProcess(x_trans, method = c("center", "scale"))
x_treino <- predict(standardizer, x_trans)
y_treino <- log1p(treino_sf[, 1])
```





Para a predição da estação 46998000, será utilizado apenas os dados das vazões da semana anterior, incluindo a vazão da própria estação 46998000. Além disso, mesmo que os dados estejam padronizados, a vazão da semana seguinte será predita com a transformação $\log(x+1)$. Para conjunto de teste será aplicado a transformação $\exp(x) - 1$ nas predições para que a vazão seja apresentada na escala original.

Para ilustrar as transformações feitas, e o que será utilizado para ajustar os modelos, na Tabela \@ref(tab:matriz-x) é apresentado as 6 primeiras observações do conjunto de treinamento, em que na primeira coluna tem-se a vazão da semana seguinte que deseja-se prever com a transformação $\log(x+1)$.  As demais colunas são as 6 primeiras colunas das vazões da semana anterior já transformadas e padronizadas.

```{r matriz-x}
cbind(
  "$\\log(Y + 1)$" = y_treino,
  x_treino[, 1:6]
) %>%
  head(6) %>%
  kable(
    caption = paste(
      "Primeiras linhas e colunas",
      "do conjunto de treinamento,",
      "com a primeira coluna sendo a variável resposta transformada",
      "(vazão da semana seguinte)."
    ),
    booktabs = TRUE, linesep = "", escape = FALSE, digits = 3
  ) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```


### Ajuste dos modelos

Como já definido, os modelos serão comparados por validação cruzada. O método de validação cruzada escolhido foi o *k-folds*, com $k=10$, ou seja, será utilizado 9 amostras para ajustar os modelos, e uma amostra para validação. Esse processo será repetido 10 vezes. A medida utilizada para comparar os modelos será o erro médio absoluto.

Os modelos que serão ajustados são:

- Modelos lineares com regularização:
    - Lasso
    - Ridge
- Modelos baseados em árvores:
    - Floresta aleatória
    - Boosting utilizando o pacote [XGBoost](https://xgboost.ai/)
- Rede Neural

```{r}
set.seed(1)
cv_folds <- 10

folds <- sample(1:10, size = length(y_treino), replace = TRUE)
```


Para os modelos de Lasso e Ridge, primeiro foi escolhido o melhor parâmetro de penalização através da validação cruzada, utilizando as mesmas amostras já definidas pelo *k-fold*. Em seguida, dado os parâmetros de penalização que apresentaram o menor erro de validação cruzada, foi feito novamente a validação cruzada para obter o erro médio absoluto de cada *fold*


```{r}
set.seed(1)
lambda_lasso <-
  cv.glmnet(x_treino,
    y_treino,
    foldid = folds
  )$lambda.min

lambda_ridge <-
  cv.glmnet(x_treino,
    y_treino,
    foldid = folds,
    alpha = 0
  )$lambda.min
```

```{r}
scores <- list()

# Realiza a validação cruzada e obtém os erros absolutos médios.
cv_mae <- function(modelo, x, y, folds, ...) {
  unique_folds <- unique(folds)
  sapply(unique_folds, function(fold) {
    idx_val <- folds == fold

    x_tr <- x[!idx_val, ]
    y_tr <- y[!idx_val]
    x_val <- x[idx_val, ]
    y_val <- y[idx_val]


    fit_ <- modelo(x_tr, y_tr, ...)

    preds_ <- predict(fit_, x_val)

    MAE(preds_, y_val)
  })
}
```


Maior parte do modelo de floresta aleatória foi ajustado com os valores padrão da função `randomForest` do pacote com o mesmo nome. Mas para previnir sobreajuste foi definido que a profundidade máxima de cada árvore seria 15.

O modelo de Boosting consegue facilmente sobreajustar os dados de treino. Porém, o pacote XGBoost fornece diversos hiper-parâmetros para controlar o ajuste. Por isso foi utilizada uma taxa de aprendizagem $\eta = 0.01$,  profundidade máxima da árvore 4, em cada árvore utilizava apenas 70\% das observações e dos preditores. Além disso, a perda mínima para a prolongar a árvore seria 0.6, foi utilizada regularização de primeira ordem e foi utilizado o número de árvores igual a 1000.


```{r scores, cache=TRUE}

set.seed(115)

scores[["Lasso"]] <- cv_mae(glmnet,
  x_treino, y_treino, folds,
  alpha = 1, lambda = lambda_lasso
)
scores[["Ridge"]] <- cv_mae(glmnet,
  x_treino, y_treino, folds,
  alpha = 0, lambda = lambda_ridge
)

scores[["Floresta Aleatória"]] <- cv_mae(randomForest,
  x_treino, y_treino, folds,
  maxnodes = 15
)


params <- list(
  objective = "reg:squarederror",
  eta = .01, # taxa de aprendizagem baixa para evitar overfitting.
  max_depth = 4, # A profundidade máxima da árvore
  gamma = .6, # Perda mínima para uma nova partição  da folha.
  subsample = .7, # Utiliza menos dados para ajustar o modelo
  colsample_bytree = .7, # Utiliza menos colunas
  reg_alpha = 5e-5, # Regularização L1, similar ao lasso
  nthread = parallel::detectCores() - 1 # número de processadores lógicos
  # utilizados.
)

scores[["Boosting"]] <- cv_mae(xgboost,
  x_treino, y_treino, folds,
  nrounds = 1000, params = params, verbose = 0
)
```

Para o modelo de redes neurais, utilizou-se um modelo simples que foi é treinado em 50 épocas em lotes de tamanho 64 (`batch_size`). A estrutura do modelo é:

- camada `dense` com 128 neurônios e ativação sigmóide;
- camada `dense` com 64 neurônios e ativação sigmóide;
- a última camada é uma `dense` com ativação linear;

```{r rede-neural}
cria_rede_sf <- function() {
  modelo <- keras_model_sequential() %>%
    layer_dense(128, activation = "sigmoid", input_shape = ncol(x_treino)) %>%
    layer_dense(64, activation = "sigmoid") %>%
    layer_dense(1)

  modelo %>%
    compile(
      optimizer = optimizer_adam(),
      loss = loss_mean_squared_error()
    )
}

tensorflow::set_random_seed(1234)

# Não consegui aplicar a minha função para o keras, logo será feito na mao
scores[["Rede Neural"]] <- sapply(unique(folds), function(fold) {
  idx_val <- folds == fold

  x_tr <- x_treino[!idx_val, ]
  y_tr <- y_treino[!idx_val]
  x_val <- x_treino[idx_val, ]
  y_val <- y_treino[idx_val]

  modelo <- cria_rede_sf()

  modelo %>% fit(x_tr, y_tr, verbose = 0, batch_size = 64, epochs = 50)

  modelo %>%
    predict(x_val) %>%
    MAE(y_val)
})
```


*comparar as estruturas das redes antigas, comparação relu e sigmoide e rede com 2 camadas escondidas ou com 1*


### Comparação dos modelos

Com a validação cruzada foi obtido diversos erros quadráticos médios para os modelos ajustados. Na Figura \@ref(fig:boxplot-scores) essas medidas são apresentadas em um boxplot, com a média sendo apresentada em um ponto em vermelho. E na Tabela \@ref(tab:media-scores) é apresentado a média e o desvio padrão estimados para cada modelo.

```{r boxplot-scores, fig.cap="Boxplot do erro médio absoluto por modelo pela validação cruzada."}
scores_tbl <- bind_cols(scores) %>%
  pivot_longer(everything(), names_to = "Modelo", values_to = "mae")
scores_tbl %>%
  ggplot(aes(Modelo, mae)) +
  geom_boxplot() +
  stat_summary(
    fun = mean, geom = "point", shape = 20,
    size = 2, color = "red"
  ) +
  labs(x = "Modelo", y = "Erro Médio Absoluto") +
  coord_flip()
```

```{r media-scores}
scores_tbl %>%
  group_by(Modelo) %>%
  summarise(
    media = mean(mae),
    desvio = sd(mae)
  ) %>%
  arrange(media) %>%
  kable(
    caption = paste(
      "Média e desvio do erro médio absoluto",
      "dos modelos pela validação cruzada"
    ),
    col.names = c("Modelo", "Média", "Desvio"),
    booktabs = TRUE, linesep = ""
  ) %>%
  kable_styling(latex_options = c("striped", "hold_position"))
```

Nota-se que dos modelos ajustados, o modelo de redes neurais foi o que teve o pior ajuste e a maior variabilidade pela validação cruzada. Os modelos baseados em árvore foram os que apresentaram os erros mais consistentes pela validação cruzada, e os que apresentaram o melhor ajuste no geral foram o modelo de Boosting e o Lasso.



### Escolha do modelo

Geralmente para ter melhores predições, as predições dos vários modelos de *machine learning* são misturadas. Existem diversas formas de misturar as predições, desde tomar a média delas, até construir modelos sobre essas predições.


Todos os modelos foram ajustados novamente utilizando todo o conjuto de treino. E para as predições finais, será utilizada a média ponderada de todos os modelos ajustados, em que os pesos serão definidos a partir da performance pela validação.

Após tomar a média ponderada será utilizada a transformação $\exp(x) - 1$ na média ponderada para que a vazão predita esteja na escala original da variável resposta. Logo, as predições no conjunto de teste são dadas por:
\[\hat y = \exp\{0.25 \hat y_{B} + 0.25 \hat y_{L} +
0.25 \hat y_{F} + 0.2 \hat y_{R} + 0.05 \hat y_{RN}\} - 1,\]
onde $\hat y_{B}, \hat y_{L}, \hat y_{F}, \hat y_{R}, \hat y_{RN},$ são as predições de Boosting, Lasso, Floresta aleatória, Ridge e Rede Neural, respectivamente.



```{r}
set.seed(549)
lasso_full <- glmnet(x_treino, y_treino, alpha = 1, lambda = lambda_lasso)
ridge_full <- glmnet(x_treino, y_treino, alpha = 0, lambda = lambda_ridge)
rf_full <- randomForest(x_treino, y_treino, ntree = 500, maxnodes = 15,
                        importance = TRUE)
xgboost_full <- xgboost(x_treino, y_treino,
  nrounds = 1000, params = params,
  verbose = 0
)

rn_full <- cria_rede_sf()
rn_full %>% fit(x_treino, y_treino,
  verbose = 0,
  batch_size = 64, epochs = 50
)


mistura_predicoes <- function(x) {
  predicao <- .25 * predict(xgboost_full, x) +
    .25 * predict(lasso_full, x) +
    .25 * predict(rf_full, x) +
    .2 * predict(ridge_full, x) +
    .05 * predict(rn_full, x)

  # Evita que a predicao saia como matriz ou dataframe por causa do lasso
  if (is.matrix(predicao) || is.data.frame(predicao)) {
    return(as.vector(predicao))
  }
  predicao
}
```

```{r}
x_teste <- as.matrix(teste_sf[, colnames(x_treino)]) %>%
  log1p() %>% # Realiza a transformação log(x+1)
  predict(standardizer, .) # Padroniza

predicoes <- expm1(mistura_predicoes(x_teste))

write.csv(data.frame(y_pred = predicoes),
  file = glue("sf_{nusp}_{meunome}.csv")
)
```

```{r}
preds = list(
    xgb = expm1(predict(xgboost_full, x_treino)),
    rf = expm1(predict(rf_full, x_treino)),
    lasso = expm1(predict(lasso_full, x_treino)),
    ridge = expm1(predict(ridge_full, x_treino)),
    rn = expm1(predict(rn_full, x_treino)),
    mistura = expm1(mistura_predicoes(x_treino))
)

sapply(preds, MAE, obs = treino_sf$Y)
```

```{r importancias, fig.cap="Importância de variável", fig.subcap=c("Boosting", "Floresta Aleatória", "Lasso", "Ridge"), out.width="50%", fig.ncol=2}
imp_xgb = xgb.importance(colnames(x_treino), xgboost_full)

xgb.ggplot.importance(imp_xgb, top_n = n_var, ) +
    labs(title = NULL, x = "Estação", y = "Importância")

width = .5

importance(rf_full) %>%
    as_tibble(rownames = "termo") %>%
    slice_max(`%IncMSE`, n=n_var) %>%
    ggplot(aes(reorder(termo, `%IncMSE`, mean), `%IncMSE`)) +
    geom_col(fill = "dodgerblue3", width = width) +
    coord_flip() +
    labs(x = "Estação", y = "Importância")

# Absoluto do coeficiente para Lasso e Ridge
varImp(lasso_full, lambda_lasso) %>%
    rownames_to_column("termo") %>%
    slice_max(Overall, n = n_var) %>%
    ggplot(aes(reorder(termo, Overall, mean), Overall)) +
    geom_col(fill = "dodgerblue3", width = width) +
    coord_flip() +
    labs(x = "Estação", y = "Importância")

varImp(ridge_full, lambda_ridge) %>%
    rownames_to_column("termo") %>%
    slice_max(Overall, n = n_var) %>%
    ggplot(aes(reorder(termo, Overall, mean), Overall)) +
    geom_col(fill = "dodgerblue3", width = width) +
    coord_flip() +
    labs(x = "Estação", y = "Importância")
```

